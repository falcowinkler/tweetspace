job.name=GobblinKafkaQuickStart
job.group=GobblinKafka
job.description=Gobblin quick start job for Kafka
job.lock.enabled=false

kafka.brokers=${env:KAFKA_BROKERS}
kafka.deserializer.type=CONFLUENT_AVRO
kafka.schema.registry.class=gobblin.source.extractor.extract.kafka.ConfluentKafkaSchemaRegistry
kafka.schema.registry.url=${env:SCHEMA_REG_URL}

fs.uri=${env:HADOOP_FS_URI}
writer.fs.uri=${fs.uri}
state.store.fs.uri=${fs.uri}

# don't try to pull the offset topic and find a schema for it
topic.whitelist=^(?!_).+

source.class=org.apache.gobblin.source.extractor.extract.kafka.KafkaDeserializerSource
extract.namespace=org.apache.gobblin.extract.kafka

writer.builder.class=org.apache.gobblin.writer.AvroDataWriterBuilder
writer.destination.type=HDFS
writer.output.format=AVRO
writer.file.path.type=tablename

data.publisher.type=org.apache.gobblin.publisher.BaseDataPublisher

mr.job.max.mappers=1

metrics.reporting.file.enabled=true
metrics.log.dir=/gobblin-kafka/metrics
metrics.reporting.file.suffix=txt

bootstrap.with.offset=earliest

mr.job.root.dir=/gobblin-kafka-avro/working
state.store.dir=/gobblin-kafka-avro/state-store
task.data.root.dir=/jobs/kafkaetl/gobblin/gobblin-kafka-avro/task-data
data.publisher.final.dir=/gobblin-kafka-avro/job-output
